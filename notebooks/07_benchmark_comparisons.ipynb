{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 07 â€” Benchmark Comparisons\n",
        "Compare ARIMA-only and ARIMA+LSTM against simple correlation baselines."
      ],
      "metadata": {
        "id": "jF8KIBMszhRa"
      },
      "id": "jF8KIBMszhRa"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "corr_df = pd.read_parquet(\"../data/processed/rolling_corr_sample.parquet\")"
      ],
      "metadata": {
        "id": "5yIeWWEzzgdD"
      },
      "id": "5yIeWWEzzgdD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baselines\n",
        "def baseline_full_historical(train, test):\n",
        "    mu = float(np.mean(train))\n",
        "    return np.full_like(test, mu, dtype=\"float32\")\n",
        "\n",
        "def baseline_constant_correlation(train, test):\n",
        "    # same as mean baseline (kept separate for clarity)\n",
        "    return baseline_full_historical(train, test)\n",
        "\n",
        "def baseline_last_value(train, test):\n",
        "    last = float(train[-1])\n",
        "    return np.full_like(test, last, dtype=\"float32\")\n",
        "\n",
        "def metrics(y_true, y_hat):\n",
        "    y_true = y_true.astype(\"float32\")\n",
        "    y_hat = y_hat.astype(\"float32\")\n",
        "    mse = float(np.mean((y_true - y_hat)**2))\n",
        "    mae = float(np.mean(np.abs(y_true - y_hat)))\n",
        "    return mse, mae"
      ],
      "metadata": {
        "id": "vtCczH1N074R"
      },
      "id": "vtCczH1N074R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate baselines on one series\n",
        "series = corr_df.columns[0]\n",
        "y = corr_df[series].dropna().values.astype(\"float32\")\n",
        "\n",
        "n = len(y)\n",
        "train_end = int(0.7*n)\n",
        "val_end = int(0.85*n)\n",
        "\n",
        "train = y[:train_end]\n",
        "test  = y[val_end:]\n",
        "\n",
        "pred_mean = baseline_full_historical(train, test)\n",
        "pred_last = baseline_last_value(train, test)\n",
        "\n",
        "print(\"Mean baseline:\", metrics(test, pred_mean))\n",
        "print(\"Last-value baseline:\", metrics(test, pred_last))"
      ],
      "metadata": {
        "id": "-w2g4GJn1p2h"
      },
      "id": "-w2g4GJn1p2h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Table template for final reporting\n",
        "rows = []\n",
        "rows.append({\"model\": \"Mean (Full Historical)\", \"mse\": metrics(test, pred_mean)[0], \"mae\": metrics(test, pred_mean)[1]})\n",
        "rows.append({\"model\": \"Last Value\", \"mse\": metrics(test, pred_last)[0], \"mae\": metrics(test, pred_last)[1]})\n",
        "\n",
        "pd.DataFrame(rows).sort_values(\"mse\")"
      ],
      "metadata": {
        "id": "a9BJXmWJ4o5U"
      },
      "id": "a9BJXmWJ4o5U",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}